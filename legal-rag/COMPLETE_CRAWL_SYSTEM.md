# ALMQUIST Legal RAG - Complete Crawl System

**Status:** âœ… PRODUCTION - RUNNING
**Version:** 2.0
**Date:** 2025-11-30
**Coverage:** ALL Czech Courts (~546,000+ decisions)

---

## ğŸ¯ Overview

KompletnÃ­ autonomnÃ­ systÃ©m pro crawlovÃ¡nÃ­ **VÅ ECH ÄeskÃ½ch soudÅ¯** vÄetnÄ›:
- **NejvyÅ¡Å¡Ã­ soud (NS)** - specializovanÃ¡ sbÃ­rka
- **VÅ¡echny soudy ÄŒR** - pÅ™es oficiÃ¡lnÃ­ Justice.cz API
- **Resource monitoring** - CPU, GPU, Disk, Memory
- **ParalelnÃ­ bÄ›h** - 2 crawlery souÄasnÄ›
- **Auto-stop** - pÅ™i pÅ™ekroÄenÃ­ limitÅ¯

---

## ğŸ“Š Data Coverage

### Justice.cz API - ALL COURTS
**Total: ~546,000 rozhodnutÃ­** (2020-2025)

```
2021: 150,940 rozhodnutÃ­
2022: 181,864 rozhodnutÃ­
2023:  85,465 rozhodnutÃ­
2024:  61,217 rozhodnutÃ­
2025:  66,576 rozhodnutÃ­
```

**PokrytÃ© soudy:**
- âœ… NejvyÅ¡Å¡Ã­ soud (NS)
- âœ… ÃšstavnÃ­ soud (ÃšS)
- âœ… NejvyÅ¡Å¡Ã­ sprÃ¡vnÃ­ soud (NSS)
- âœ… VrchnÃ­ soud v Praze
- âœ… VrchnÃ­ soud v Olomouci
- âœ… VÅ¡echny krajskÃ© soudy (15)
- âœ… VÅ¡echny okresnÃ­ soudy

### NS Specialized Collection
**SbÃ­rka.nsoud.cz:** ~1,328 strÃ¡nek specializovanÃ© sbÃ­rky

---

## ğŸš€ Running Crawlers

### Current Status

```bash
screen -ls
```

**Active crawlers:**
1. `ns_supreme` - NS specialized collection
2. `justice_all` - ALL courts via API

### Monitor Progress

```bash
# Attach to NS crawler
screen -r ns_supreme

# Attach to Justice API crawler
screen -r justice_all

# Check database
sqlite3 /home/puzik/almquist_legal_sources.db \
  "SELECT COUNT(*) FROM court_decisions"

# Resource status
python3 /home/puzik/almquist_resource_monitor.py
```

---

## ğŸ“ Components

### 1. Resource Monitor (`almquist_resource_monitor.py`)

Monitors system resources and enforces limits:
- **CPU:** â‰¤ 80%
- **GPU:** â‰¤ 80%
- **Disk:** â‰¤ 90%
- **Memory:** â‰¤ 85%

**Usage:**
```python
from almquist_resource_monitor import ResourceMonitor

monitor = ResourceMonitor()
if not monitor.check_all():
    print("Resource limits exceeded!")
```

### 2. Justice API Crawler (`almquist_justice_api_crawler.py`)

Crawls ALL Czech courts via official REST API.

**Features:**
- REST API: `https://rozhodnuti.justice.cz/api/opendata`
- Pagination: 100 decisions per page
- Hierarchical: year â†’ month â†’ day â†’ page
- Metadata: ECLI, keywords, affected laws
- Full text: Available via detail endpoint

**API Structure:**
```
GET /api/opendata                  â†’ years list
GET /api/opendata/2024            â†’ months in 2024
GET /api/opendata/2024/11         â†’ days in Nov 2024
GET /api/opendata/2024/11/29?page=0 â†’ decisions on day
```

**Run:**
```bash
python3 almquist_justice_api_crawler.py
```

### 3. NS Specialized Crawler (`almquist_legal_court_decisions_crawler.py`)

Crawls NS specialized collection (sbÃ­rka rozhodnutÃ­).

**Features:**
- Archive URL: `/nove-vydana-rozhodnuti-ve-sbirka/`
- Pagination: `/strana/{page}/`
- ~1,328 pages available
- Detailed case information

**Run:**
```bash
python3 almquist_legal_court_decisions_crawler.py
```

---

## âš™ï¸ Configuration

### Pause Between Requests
```python
self.pause_between_requests = 30  # seconds
```

**Rationale:** 30 seconds ensures we don't overload court servers.

### Resource Limits
```python
ResourceMonitor(
    cpu_limit=80,    # CPU usage %
    disk_limit=90,   # Disk usage %
    mem_limit=85,    # Memory usage %
    gpu_limit=80     # GPU usage %
)
```

**Auto-stop:** Crawlers automatically stop if any limit is exceeded.

---

## ğŸ—‚ï¸ Database Schema

**Table: `court_decisions`**

```sql
CREATE TABLE court_decisions (
    id INTEGER PRIMARY KEY,
    case_number TEXT,           -- JednacÃ­ ÄÃ­slo
    court_level TEXT,           -- supreme/appellate/regional/district
    court_name TEXT,            -- NÃ¡zev soudu
    decision_type TEXT,         -- rozsudek/usnesenÃ­/nÃ¡lez
    decision_date TEXT,         -- Datum vydÃ¡nÃ­
    ecli TEXT UNIQUE,           -- ECLI identifier
    keywords TEXT,              -- JSON array
    affected_laws TEXT,         -- JSON array
    summary TEXT,               -- PÅ™edmÄ›t Å™Ã­zenÃ­
    full_text TEXT,             -- CelÃ© rozhodnutÃ­
    source_url TEXT,            -- URL zdroje
    added_to_rag INTEGER DEFAULT 0,
    created_at TEXT DEFAULT CURRENT_TIMESTAMP,
    updated_at TEXT DEFAULT CURRENT_TIMESTAMP
);
```

---

## ğŸ“ˆ Expected Timeline

### NS Crawler
- Pages: 1,328
- Pause: 30s/page
- Minimum: ~11 hours (pauses only)
- **Estimate: 15-20 hours**

### Justice API Crawler
- Decisions: ~546,000
- Requests: ~5,460 (100/page)
- Pause: 30s/request
- Minimum: ~45 hours (pauses only)
- **Estimate: 50-70 hours (2-3 days)**

---

## ğŸ”„ Workflow

```
1. NS Crawler (ns_supreme)
   â†“
   Crawls sbirka.nsoud.cz
   â†“
   Saves to almquist_legal_sources.db
   â†“
   Monitors CPU/GPU/Disk/Memory
   â†“
   Auto-stops if limits exceeded

2. Justice API Crawler (justice_all)
   â†“
   Fetches available years
   â†“
   For each year â†’ month â†’ day
   â†“
   Paginates through decisions (100/page)
   â†“
   Saves metadata + full text
   â†“
   Monitors resources
   â†“
   Auto-stops if limits exceeded

3. After Completion
   â†“
   Run RAG integration
   â†“
   python3 almquist_legal_rag_integration.py
   â†“
   Generates embeddings for ALL decisions
   â†“
   Updates FAISS index
```

---

## ğŸ¯ Integration to RAG

After crawlers complete:

```bash
# Integrate all new decisions into RAG
python3 /home/puzik/almquist_legal_rag_integration.py

# Check statistics
python3 /home/puzik/almquist_legal_stats.py

# Run test suite
python3 /home/puzik/almquist_legal_rag_test_suite.py
```

---

## ğŸ“Š Monitoring Commands

```bash
# Check crawler status
screen -ls
ps aux | grep almquist

# Database statistics
sqlite3 /home/puzik/almquist_legal_sources.db <<EOF
SELECT
  court_level,
  COUNT(*) as total,
  SUM(CASE WHEN added_to_rag=1 THEN 1 ELSE 0 END) as in_rag
FROM court_decisions
GROUP BY court_level
ORDER BY total DESC;
EOF

# Disk usage
df -h /

# Resource status
python3 /home/puzik/almquist_resource_monitor.py

# Crawler logs
tail -f /tmp/ns_supreme_crawler.log
tail -f /tmp/justice_all_crawler.log
```

---

## ğŸ›‘ Manual Control

### Stop Crawlers
```bash
# Stop NS crawler
screen -S ns_supreme -X quit

# Stop Justice API crawler
screen -S justice_all -X quit

# Stop all
pkill -f "almquist_legal"
```

### Resume Crawlers
```bash
# Start NS crawler
screen -dmS ns_supreme bash -c \
  "python3 almquist_legal_court_decisions_crawler.py 2>&1 | tee /tmp/ns_supreme_crawler.log"

# Start Justice API crawler
screen -dmS justice_all bash -c \
  "python3 almquist_justice_api_crawler.py 2>&1 | tee /tmp/justice_all_crawler.log"
```

---

## ğŸ”® Future Enhancements

### Short-term
- [ ] Download full text for all decisions (via detail endpoints)
- [ ] Implement incremental updates (daily cron)
- [ ] Add decision quality scoring
- [ ] Web dashboard for monitoring

### Long-term
- [ ] Real-time notification on new decisions
- [ ] Automatic categorization by legal area
- [ ] Citation network analysis
- [ ] Multi-language support (Slovak, EU courts)

---

## ğŸš¨ Troubleshooting

### Crawler Not Running
```bash
# Check if process exists
ps aux | grep almquist

# Check screen sessions
screen -ls

# Check logs
tail -100 /tmp/ns_supreme_crawler.log
tail -100 /tmp/justice_all_crawler.log
```

### Database Locked
```bash
# Check if other processes are using DB
lsof | grep almquist_legal_sources.db

# Kill if needed
pkill -9 -f "almquist_legal"
```

### Resource Limits Hit
```bash
# Check current usage
python3 /home/puzik/almquist_resource_monitor.py

# Free up disk space
df -h
rm -rf /tmp/old_logs

# Kill resource-heavy processes
top
```

---

## ğŸ“ Support

**Logs:** `/tmp/ns_supreme_crawler.log`, `/tmp/justice_all_crawler.log`
**Database:** `/home/puzik/almquist_legal_sources.db`
**RAG Data:** `/home/puzik/almquist_legal_rag/`

---

**ğŸš€ PRODUCTION READY - Autonomous Legal Crawl System**

**ALL Czech Courts | ~546,000+ Decisions | Resource Monitored | Auto-stop Protected**
